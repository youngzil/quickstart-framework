- []()
- []()
- []()
- []()
- []()


-------------------------------------------------------------------------


1、前言
2、I/O概念
3、Java零拷贝
4、Netty零拷贝
5、其他零拷贝
6、总结



零拷贝参考
https://juejin.im/post/5cad6f1ef265da039f0ef5df



缓冲区
虚拟内存
零拷贝提供了两种方式分别是：mmap+write方式，sendfile方式
java零拷贝：MappedByteBuffer 和 Channel-to-Channel传输
DMA直接内存访问（Direct Memory Access，DMA）


缓冲区是所有I/O的基础，I/O讲的无非就是把数据移进或移出缓冲区；进程执行I/O操作，就是向操作系统发出请求，让它要么把缓冲区的数据排干(写)，要么填充缓冲区(读)；




![进程读取数据流程](../images/iobuffer.png "ReferencePicture")

读写请求流程：

进程发起read请求之后，内核接收到read请求之后，会先检查内核空间中是否已经存在进程所需要的数据，如果已经存在，则直接把数据copy给进程的缓冲区；如果没有内核随即向磁盘控制器发出命令，要求从磁盘读取数据，磁盘控制器把数据直接写入内核read缓冲区，这一步通过DMA完成；接下来就是内核将数据copy到进程的缓冲区；

如果进程发起write请求，同样需要把用户缓冲区里面的数据copy到内核的socket缓冲区里面，然后再通过DMA把数据copy到网卡中，发送出去；


虚拟内存：
1.一个以上的虚拟地址可以指向同一个物理内存地址，
2.虚拟内存空间可大于实际可用的物理地址；



mmap+write方式
使用mmap+write方式代替原来的read+write方式，mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系；这样就可以省掉原来内核read缓冲区copy数据到用户缓冲区，但是还是需要内核read缓冲区将数据copy到内核socket缓冲区


sendfile方式
sendfile系统调用在内核版本2.1中被引入，目的是简化通过网络在两个通道之间进行的数据传输过程。
sendfile系统调用的引入，不仅减少了数据复制，还减少了上下文切换的次数


java零拷贝
1、MappedByteBuffer：java nio提供的FileChannel提供了map()方法，
大致意思就是通过native方法获取内存映射的地址，如果失败，手动gc再次映射；最后通过内存映射的地址实例化出MappedByteBuffer，MappedByteBuffer本身是一个抽象类，其实这里真正实例话出来的是DirectByteBuffer；
MapMode：映射的模式，可选项包括：READ_ONLY，READ_WRITE，PRIVATE；
如果在一个没有读权限的文件上启用READ_ONLY，将抛出NonReadableChannelException；
PRIVATE模式表示写时拷贝的映射

2、Channel-to-Channel传输
通过FileChannel的transferTo()方法 和 transferFrom()方法


RocketMQ的消息采用顺序写到commitlog文件，然后利用consume queue文件作为索引；RocketMQ采用零拷贝mmap+write的方式来回应Consumer的请求；

同样kafka中存在大量的网络数据持久化到磁盘和磁盘文件通过网络发送的过程，kafka使用了sendfile零拷贝方式；




https://blog.csdn.net/mofabang/article/details/49613771
https://nieyong.github.io/wiki_cpu/CPU%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84-DMA.html

DMA直接内存访问（Direct Memory Access，DMA）是计算机科学中的一种内存访问技术。它允许某些计算机内部的硬件子系统（计算机外设），可以独立地直接读写系统内存，而不需中央处理器（CPU）介入处理 。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。

DMA是所有现代计算机的重要特色，它允许不同速度的硬件设备来沟通，而不需要依于中央处理器的大量中断负载。否则，中央处理器需要从来源把每一片段的数据复制到寄存器，然后把它们再次写回到新的地方。在这个时间中，中央处理器对于其他的工作来说就无法使用。
DMA传输常使用在将一个内存区从一个设备复制到另外一个。当中央处理器初始化这个传输动作，传输动作本身是由DMA控制器来实行和完成。
典型的例子就是移动一个外部内存的区块到芯片内部更快的内存去。像是这样的操作并没有让处理器工作拖延，使其可以被重新调度去处理其他的工作。


在实现DMA传输时，是由DMA控制器直接掌管总线，因此，存在着一个总线控制权转移问题。
即DMA传输前，CPU要把总线控制权交给DMA控制器，而在结束DMA传输后，DMA控制器应立即把总线控制权再交回给CPU。
由此可见，DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场的过程，通过硬件为RAM与I/O设备开辟一条直接传送数据的通路，使CPU的效率大为提高。



缓存一致性问题
DMA会导致缓存一致性问题。想像中央处理器带有缓存与外部内存的情况，DMA的运作则是去访问外部内存，当中央处理器访问外部内存某个地址的时候，暂时先将新的值写入缓存中，但并未将外部内存的数据更新，若在缓存中的数据尚未更新到外部内存前发生了DMA，则DMA过程将会读取到未更新的数据。
相同的，如果外部设备写入新的值到外部内存内，则中央处理器若访问缓存时则会访问到尚未更新的数据。

这些问题可以用两种方法来解决：
1、缓存同调系统（Cache-coherent system）：以硬件方法来完成，当外部设备写入内存时以一个信号来通知缓存控制器某内存地址的值已经过期或是应该更新数据。
2、非同调系统（Non-coherent system）：以软件方法来完成，操作系统必须确认缓存读取时，DMA程序已经开始或是禁止DMA发生。
第二种的方法会造成DMA的系统负担。

